{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc7c4b9-b0b7-4f0f-bdf6-4acffd9c9e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(768, 1024, 3)\n",
      "(768, 1024)\n"
     ]
    }
   ],
   "source": [
    "from utils.FloorplanToBlenderLib import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "from IPython.display import display\n",
    "\n",
    "img_path = \"Images/test5.jpg\"\n",
    "\n",
    "# Read floorplan image\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Create blank image\n",
    "height, width, channels = img.shape\n",
    "blank_image = np.zeros((height,width,3), np.uint8)\n",
    "\n",
    "# Grayscale image\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect outer Contours (simple floor or roof solution), paint them red on blank_image\n",
    "contour, contour_img = detect.detectOuterContours(gray, blank_image, color=(255, 0, 0))\n",
    "\n",
    "gray_wall_filter = detect.wall_filter(gray)\n",
    "\n",
    "gray_wall_filter = ~gray_wall_filter\n",
    "\n",
    "rooms, colored_rooms = detect.find_rooms(gray_wall_filter.copy())\n",
    "\n",
    "gray_rooms =  cv2.cvtColor(colored_rooms, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# get box positions for rooms\n",
    "boxes_rooms, room_img = detect.detectPreciseBoxes(gray_rooms, gray_rooms)\n",
    "\n",
    "\n",
    "# create wall image (filter out small objects from image)\n",
    "wall_img = detect.wall_filter(gray)\n",
    "# wall_img = cv2.cvtColor(wall_img, cv2.COLOR_GRAY2BGR)\n",
    "# detect walls\n",
    "# boxes_walls, img = detect.detectPreciseBoxes(wall_img)\n",
    "\n",
    "\n",
    "\n",
    "# display(Image.fromarray(contour_img))\n",
    "# display(Image.fromarray(colored_rooms))\n",
    "# display(Image.fromarray(wall_img))\n",
    "\n",
    "# print(type(contour_img))\n",
    "print(type(colored_rooms))\n",
    "print(type(wall_img))\n",
    "\n",
    "# print(contour_img.shape)\n",
    "print(colored_rooms.shape)\n",
    "print(wall_img.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28806434-b05d-4019-bd1c-47bbb3a470f9",
   "metadata": {},
   "source": [
    "### combine gray detect_room & detect_wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb43b239-c073-4570-aa87-e91ae7aeb0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1024x768 at 0x20F12F87CA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine1 = cv2.addWeighted(room_img, 1, wall_img, 1, 0)\n",
    "# display(Image.fromarray(combine1))\n",
    "\n",
    "combine2 = cv2.bitwise_or(wall_img, room_img)\n",
    "display(Image.fromarray(combine2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de1d64-3585-45fb-9403-4c5deed5bc56",
   "metadata": {},
   "source": [
    "### DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3579194d-e65a-408b-8ca3-14be5532d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Akademic\\Programming\\Bootcamp\\iSpan_BigData\\99_Project\\3_專題執行\\contour_detection\\Detection_testing_v0\\utils\\plotting.py:611: UserWarning: Trying to register the cmap 'rooms_furu' which already exists.\n",
      "  cm.register_cmap(cmap=cmap3)\n",
      "D:\\Documents\\Akademic\\Programming\\Bootcamp\\iSpan_BigData\\99_Project\\3_專題執行\\contour_detection\\Detection_testing_v0\\utils\\post_prosessing.py:334: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for pol in polygon_union:\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "# Import library\n",
    "from utils.FloorplanToBlenderLib import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import cv2 \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import get_model\n",
    "from utils.loaders import FloorplanSVG, DictToTensor, Compose, RotateNTurns\n",
    "from utils.plotting import segmentation_plot, polygons_to_image, draw_junction_from_dict,           discrete_cmap\n",
    "discrete_cmap()\n",
    "from utils.post_prosessing import split_prediction, get_polygons, split_validation\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "rot = RotateNTurns()\n",
    "\n",
    "model = get_model('hg_furukawa_original', 51)\n",
    "n_classes = 44\n",
    "split = [21, 12, 11]\n",
    "model.conv4_ = torch.nn.Conv2d(256, n_classes, bias=True, kernel_size=1)\n",
    "model.upsample = torch.nn.ConvTranspose2d(n_classes, n_classes, kernel_size=4, stride=4)\n",
    "checkpoint = torch.load('model_best_val_loss_var.pkl')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "# Create tensor for pytorch\n",
    "# img = cv2.imread(img_path)\n",
    "parts_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # correct color channels\n",
    "\n",
    "# Image transformation to range (-1,1)\n",
    "parts_img = 2 * (parts_img / 255.0) - 1\n",
    "\n",
    "# Move from (h,w,3)--->(3,h,w) as model input dimension is defined like this\n",
    "parts_img = np.moveaxis(parts_img, -1, 0)\n",
    "\n",
    "# Convert to pytorch, enable cuda\n",
    "parts_img = torch.tensor([parts_img.astype(np.float32)]).cuda()\n",
    "n_rooms = 12\n",
    "n_icons = 11\n",
    "\n",
    "with torch.no_grad():\n",
    "    #Check if shape of image is odd or even\n",
    "    size_check = np.array([parts_img.shape[2],parts_img.shape[3]])%2\n",
    "\n",
    "    height = parts_img.shape[2] - size_check[0]\n",
    "    width = parts_img.shape[3] - size_check[1]\n",
    "\n",
    "    parts_img_size = (height, width)\n",
    "\n",
    "    rotations = [(0, 0), (1, -1), (2, 2), (-1, 1)]\n",
    "    pred_count = len(rotations)\n",
    "    prediction = torch.zeros([pred_count, n_classes, height, width])\n",
    "    for i, r in enumerate(rotations):\n",
    "        forward, back = r\n",
    "        # We rotate first the image\n",
    "        rot_image = rot(parts_img, 'tensor', forward)\n",
    "        pred = model(rot_image)\n",
    "        # We rotate prediction back\n",
    "        pred = rot(pred, 'tensor', back)\n",
    "        # We fix heatmaps\n",
    "        pred = rot(pred, 'points', back)\n",
    "        # We make sure the size is correct\n",
    "        pred = F.interpolate(pred, size=(height, width), mode='bilinear', align_corners=True)\n",
    "        # We add the prediction to output\n",
    "        prediction[i] = pred[0]\n",
    "\n",
    "prediction = torch.mean(prediction, 0, True)\n",
    "\n",
    "\n",
    "heatmaps, rooms, icons = split_prediction(prediction, parts_img_size, split)\n",
    "polygons, types, room_polygons, room_types = get_polygons((heatmaps, rooms, icons), 0.2, [1, 2])\n",
    "\n",
    "wall_polygon_numbers=[i for i,j in enumerate(types) if j['type']=='wall']\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6d5128-1afc-4a9e-990f-335fce039ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpolygons_to_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolygons\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mroom_polygons\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mroom_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\documents\\akademic\\programming\\bootcamp\\ispan_bigdata\\99_project\\3_專題執行\\contour_detection\\detection_testing_v0\\utils\\plotting.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polygons_to_image?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54452501-232a-4fe9-bc01-53778f1969c0",
   "metadata": {},
   "source": [
    "### Try to solve plot -> image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504cd3e5-c896-478a-8cc6-10fefcfed9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1024)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not save to PNG for display",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\PngImagePlugin.py:1229\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1229\u001b[0m     rawmode, mode \u001b[38;5;241m=\u001b[39m \u001b[43m_OUTMODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'F'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\Image.py:652\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPNG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\Image.py:2212\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2211\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2212\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# do what we can to clean up\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\PngImagePlugin.py:1231\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot write mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as PNG\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;66;03m# write minimal PNG file\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot write mode F as PNG",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\Image.py:654\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not save to PNG for display\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m b\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "\u001b[1;31mValueError\u001b[0m: Could not save to PNG for display"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=F size=1024x768 at 0x20FD1B5ABB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pol_room_seg, pol_icon_seg = polygons_to_image(polygons, types, room_polygons, room_types, height, width)\n",
    "print(pol_icon_seg.shape)\n",
    "print(type(pol_icon_seg))\n",
    "display(Image.fromarray(pol_icon_seg))\n",
    "\n",
    "\n",
    "# combine3 = cv2.bitwise_or(combine2, pol_icon_seg)\n",
    "# display(Image.fromarray(combine3))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,12))\n",
    "# ax = plt.subplot(1, 1, 1)\n",
    "# ax.axis('off')\n",
    "# iseg = ax.imshow(pol_icon_seg, cmap='icons', vmin=0, vmax=n_icons-0.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc7e99-c057-4f73-916d-1c23cb0c5edd",
   "metadata": {},
   "source": [
    "### Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c112336-64ea-4a17-8d78-d05b41260b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2img(fig):\n",
    "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "    import io\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d02ab84-68b2-485a-b3e8-45d1f9634f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Get the current figure.\n",
       "\n",
       "If there is currently no figure on the pyplot figure stack, a new one is\n",
       "created using `~.pyplot.figure()`.  (To test whether there is currently a\n",
       "figure on the pyplot figure stack, check whether `~.pyplot.get_fignums()`\n",
       "is empty.)\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\chihh\\appdata\\roaming\\python\\python39\\site-packages\\matplotlib\\pyplot.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gcf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e740668b-4b42-4353-96fa-8044d9f99167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(432x288)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=432x288 at 0x20F5982C3A0>\n",
      "(288, 432, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAFU0lEQVR4nO3dsU0cURRAUa9F4gJcwVIOkmugDUtElmiDGlZyK2TeCraADceBEwcMArTMn7tzTkryIODyhp3/d9M0fQGAmq+jBwCAjxAwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJJuRg9Qczwep9EzANu23+93o2dYAxsYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGBAxuF8Gj0CKyJgACQJGBfjr2NgSQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQNLN6AGg7rUTSH58+77gJLAtNjAAkmxgXMxWt42tft8wmg0MgCQBgzc6nE9O3IcVETAAkgQMgCQBAyBJwIAMn/jkfwIGQJKAAZDkRWZ4o7U+vpr7aP9a54VLETCIu328f/kLv34vOwgsbDdN0+gZUo7Hox8YMNR+v9+NnmEN/A8MgCQBAyBJwABIEjAAkgQMgCQBg5VxbQu8jYDBhTw/3AkPLEjAAEgSMACSBAyAJAEDIEnAAEhymO87OcyXOYfzyRUmLMJhvv/YwOBCxAuWJWAM590p4CMEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAWM415AAHyFgACQJGABJAgZAkoABq/b8cOfWbl4kYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGrNqfn0+jR2ClbkYPAPAaZ2UyR8D4FHMvnvplBFyKR4gAJNnA+BQ2LeCz2cAASBIwAJIEDIAkAQMgScC4CofzyZ1RsDECxlW4fbwfPQKwMAEDIEnAAEgSMACSBAyAJAHjKrhy43r5dClznIXIVXD2ImyPDQyAJAEDIEnAgFXzeJg5AgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJzkIEkuYO+fXi83bYwABIsoEBSTYtbGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJO2maRo9AwC8mw0MgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABI+guoRFdNN2xTsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=432x288 at 0x20F2AFD84C0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAADnCAYAAACZtwrQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAD9klEQVR4nO3dwW0TQRiA0Rj5QgFUsCkHiRrSBhInpLRBDZZohRuuwAX4uBw4cPEGeXG885H3rnMZS9GX3/bOeDfP8wNA0butNwCwloABWQIGZAkYkCVgQNb+pcXj8egrSmBT0zTtltZMYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgMKjD+bT1FoYnYECWgK3kvyNsT8CALAEDsgQMyBIwIEvAgCwBA7IEDMgSMCBLwICs/dYboOWlEwif3n+4407ABAaEmcBWeqvTxlt93YzJBAZkCRgXHc4nN24wPAEDsgQMyBIwIEvAYFC+8f07AQOyBAzI8iArF4369mXp0Y5R98vrEjBSHp+fLi98/X7fjTCE3TzPi4vH43F5EeAOpmnaLa35DAzIEjAgS8CALAEDsgQMyBIwNuXaHv6FgLHKjy8fhYfNCRiQJWBAloABWQIGZAkYkOUwN6sczidX2HAXDnNzc+LFCATszjw7BbcjYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgN2Za2jgdgQMyBIwIEvAgCwBg4H4xfPrCBiQJWBAloABWQIGZAkYkCVgQJaAwUB+fv629RZS9ltvAPjDWdnrCNgNLD146I8RXpe3kECWCewGTFqwDRMYkCVgQJaAAVkCBmQJWNDhfHJnFDwIWNLj89PWW4AhCBiQJWBAloABWQIGZAlYkCtX/l++Xb6Os5BBzl7CbyYwIEvAgCwBg4H4eOA6AgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVnOQkKAX3+/zAQGZJnAIOCtT1pLTGBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQJaAAVkCBmQJGJAlYECWgAFZAgZkCRiQJWBAloABWQIGZAkYkCVgQNZunuet9wCwigkMyBIwIEvAgCwBA7IEDMgSMCDrF9zFVtuCxjmJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# plt.figure(figsize=(12,12))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.axis('off')\n",
    "iseg = ax.imshow(pol_icon_seg, cmap='icons', vmin=0, vmax=n_icons-0.1)\n",
    "fig = plt.gcf()\n",
    "print(fig)\n",
    "new_img = fig2img(fig)\n",
    "print(new_img)\n",
    "new_img_nparr = np.array(new_img)\n",
    "# new_img_nparr.resize(768, 1024, 3)\n",
    "\n",
    "print(new_img_nparr.shape)\n",
    "display(Image.fromarray(new_img_nparr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99332aa0-25c5-487c-9dda-9251993398b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:214: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combine3 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbitwise_or\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombine2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_img_nparr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display(Image\u001b[38;5;241m.\u001b[39mfromarray(combine3))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:214: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "combine3 = cv2.bitwise_or(combine2, new_img_nparr)\n",
    "display(Image.fromarray(combine3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e77f6-9825-48db-b6b0-f51a9b1c9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "# 產生遮罩影像\n",
    "maskImg = Image.new(\"L\", (720, 480))\n",
    "\n",
    "# 繪製遮罩區域\n",
    "maskDraw = ImageDraw.Draw(maskImg)\n",
    "maskDraw.ellipse((50, 50, 470, 430), fill=255)\n",
    "\n",
    "# 模糊化\n",
    "maskImg = maskImg.filter(ImageFilter.GaussianBlur(30))\n",
    "\n",
    "# 顯示遮罩影像\n",
    "maskImg.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
